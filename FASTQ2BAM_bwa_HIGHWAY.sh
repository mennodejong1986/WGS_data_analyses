#!/bin/bash
# This script generates and filters bam files. 
# Scroll to bottom of script for more information on SAM/BAM format, more particulary sam flag, alignment score and mapping quality

# Note, this script does not apply indel realignment.
# It is assumed that genotype calling from the final bam-files will be performed using bcftools mpileup (with the BAQ score calculating not disabled. I.e. do NOT set the option -B, --no-BAQ.)

# IF NEEDED, INSTALL LATEST VERSION OF SAMTOOLS:
# download from htslib.org website
# tar -xvf samtools-1.20.tar.bz2
# cd samtools-1.20
# ./configure --prefix=/home/student2/software/samtools/samtools-1.20
# make
# make install



#######################
# User-defined section

# PATHS TO FILES AND SOFTWARE:
REFERENCE=/home/student12/Christopher/refgenomes/orangutan.genome.fna					# path to unzipped reference genome
REFBN=/home/student12/Christopher/refgenomes/orangutan.genome							# same, but without extension
INPUTDIR=/home/student12/Christopher/rawdata											# path to input directory (no forward slash at the end!)
OUTPUTDIR=/home/student12/Christopher/mappeddata										# path to output directory (no forward slash at the end!)
REPEATFILE=myrepeats.bed																# Optional, only needed for optional repeatmasking. This bed-file, containing a list of repetitive regions, can be generated by editing output of repeat masking software.

SAMTOOLS=samtools
PICARD=/opt/software/picard/picard.jar
BEDTOOLS=bedtools
QUALIMAP=/opt/software/qualimap/qualimap_v2.2.1/qualimap	# only needed for optional quality control step
BWA=bwa
# BWA=/opt/software/bwa-mem2-2.2.1_x64-linux				# Note: this script is still using the original bwa-mem, which is in the environment and therefore no need to specify here

NRCORES=8						# Number of cores or threads per file. For example: if working on 15 samples, and if specifying 4 cores, then usage of up to 60 cores.

# CONTROL PANEL: 				# Set the following flags one by one to TRUE. Not all the same time!
indexref=FALSE					# step 0. index reference
extractbn=TRUE					# step 0. extract base names of input files
mapdata=FALSE					# step 1. map with bwa and sort with samtools
paireddata=TRUE					# step 1. if unpaired, set to FALSE  
getstats=FALSE					# step 2. get mapping statistics
indexbam=FALSE					# step 3. index bam files
addRG=FALSE						# step 4. add readgroups	
removedup=FALSE					# step 5: remove duplicates with PICARD markduplicates
filterbam=FALSE					# step 6: filter on mapping quality and alignment score
indexbam2=FALSE					# step 7: index filtered bam files

qualitycontrol=FALSE			# step 8: quality control (optional)
removerepeats=FALSE				# step 9: remove reads which mapped to a repetitive region (optional)
indexbam3=FALSE					# step 10: index repeatmasked bam files (optional)
#######################


# OVERVIEW OF STEPS:
# step 0. index reference genome 					
# wget link 
# $BWA index -a bwtsw $REFERENCE
# /opt/software/bwa/bwa-0.7.17/bwa index -a bwtsw

# step 1a. map with bwa							
# step 1b. sort bam with samtools
# $BWA mem $REFERENCE ${INPUTDIR}/${bn1}_1.fq.gz ${INPUTDIR}/${bn1}_2.fq.gz -t 4 | samtools sort -o ${OUTPUTDIR}/${bn2}.sorted.bam	

# step 2. index bam with samtools (and get mapping statistics)		
# $SAMTOOLS index ${OUTPUTDIR}/${bn}.sorted.bam

# step 4. add readgroups											
# java -Xmx500g -jar $PICARD AddOrReplaceReadGroups I=${OUTPUTDIR}/${bn}.sorted.bam O=${OUTPUTDIR}/${bn}.sorted.RG.bam RGID=${bn} RGPL=illumina RGPU=unit1 RGLB=${bn} RGSM=${bn}

# step 5: mark duplicates with PICARD markduplicates			
# java -jar $PICARD MarkDuplicates I=${OUTPUTDIR}/${bn}.sorted.RG.bam O=${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.bam M=${OUTPUTDIR}/mark_dup_metrics.txt REMOVE_DUPLICATES=True

# step 6. filter bam on mapping quality and/alignment score
# only needed if you will not set a mapping quality filter during genotype calling, or if you want to filter on additional settings:
# $SAMTOOLS view -b -h -q 20 -e '[AS]>=100' ${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.bam > ${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.filtered.bam

# step 7. index filtered bam files						
# $SAMTOOLS index ${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.filtered.bam

# step 8. quality control
# qualimap bamqc -bam $file -outdir ${OUTPUTDIR}/QC_${bn} -outfile ${bn}_qualimap2.pdf -nt 6 -nw 30000 --paint-chromosome-limits --java-mem-size=15G

# step 9. remove repetitive regions (optional)					
# $BEDTOOLS intersect -abam  ${INPUTDIR}/${bn}.sorted.RG.dupremoved.filtered.bam -b $REPEATFILE -v > ${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.filtered.repeatmasked.bam &

# step 10. index filtered bam files						
# $SAMTOOLS index ${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.filtered.repeatmasked.bam

# optional step. create consensus fasta
# angsd -i ${bn}.sorted.RG.markdup.realigned.bam -doFasta 3 -doCounts 1 -out ${bn}.fasta
# or use script: VCF_convert2phylip.sh



if [[ "$indexref" = TRUE ]]
	then
	echo "Indexing reference..."
	$BWA index -t 30 -a bwtsw $REFERENCE		# if you map with bwa (depending on version, -t option for number of threads might not be recognised)
	# bowtie2-build ${REFBN}.fna ${REFBN}		# if you map with bowtie2
	wait
	echo "Finished indexing."
fi

if [[ "$extractbn" = TRUE ]]
	then
	ls -1 ${INPUTDIR}/*_1.fq.gz > ${OUTPUTDIR}/allsamples.txt
	rev ${OUTPUTDIR}/allsamples.txt | cut -d "/" -f1 | rev | sed 's/_1.fq.gz//g' > ${OUTPUTDIR}/allsamples.bn.txt
	rev ${OUTPUTDIR}/allsamples.txt | cut -d "/" -f1 | rev | sed 's/_1.fq.gz//g' > allsamples.bn.txt
	# rev ${OUTPUTDIR}/allsamples.txt | cut -d "/" -f1 | rev | sed 's/.QC_1.fq.gz//g' > ${OUTPUTDIR}/allsamples.bn.txt
    # rev ${OUTPUTDIR}/allsamples.txt | cut -d "/" -f1 | rev | sed 's/.QC_1.fq.gz//g' > allsamples.bn.txt
	echo "Created in input and output directory a file called 'allsamples.bn.txt', which lists the basenames of all input files."
	echo "Created in output directory a file called 'allsamples.bn.txt', which lists the basenames of all input files."
	#
	# Optionally split in smaller files to avoid overloading system:
	# split -l 12 ${OUTPUTDIR}/allsamples.bn.txt ${OUTPUTDIR}/subset
	# ls -1 ${OUTPUTDIR}/subset* > ${OUTPUTDIR}/mysubsets.txt
	fi

if [[ "$mapdata" = TRUE ]]
	then
	echo "Mapping with bwa..."
	for bn in $(cat allsamples.bn.txt)
		do
		echo $bn
		if [[ "$paireddata" = TRUE ]]
			then
			$BWA mem $REFERENCE ${INPUTDIR}/${bn}_1.fq.gz ${INPUTDIR}/${bn}_2.fq.gz -t $NRCORES | ${SAMTOOLS} sort --threads 3 -l 9 -m 2048M -o ${OUTPUTDIR}/${bn}.sorted.bam &
			else
			$BWA mem $REFERENCE ${INPUTDIR}/${bn}_1.fq.gz -t $NRCORES | ${SAMTOOLS} sort --threads $NRCORES -l 9 -m 2048M -o ${OUTPUTDIR}/${bn}.sorted.bam &
		fi
		# Note: I don't filter out unmapped reads yet (samtools view -F4), otherwise not possible to determine mapping rates. Instead, unmapped reads are removed during the final filter step.
		# However, if mapping against mitochondrial genome, then you should remove unmapped reads, in order to keep the bam-files small:
		# bwa mem $REFERENCE ${INPUTDIR}/${bn}_1.fq.gz ${INPUTDIR}/${bn}_2.fq.gz -t $NRCORES | samtools view -bhq 20 -F4 -f0x2 -t 2 | samtools sort -o ${OUTPUTDIR}/${bn}.sorted.bam &
		#
		# To speed up, optionally use bwa-mem2 -K 1000000
		# -M: set shorter split reads as secondary. Might be better to include, but since I did not do it for most deer and bear samples, for consistency I will not include this option.  
		# By default, BWA-MEM uses soft clipping for the primary alignment and hard clipping for supplementary alignments. If you specify the -Y option, also soft clipping for supplementary alignments.
		# soft-clipped: bases in 5' and 3' of the read are NOT part of the alignment.
		# hard-clipped: bases in 5' and 3' of the read are NOT part of the alignment AND those bases have been removed from the read sequence in the BAM file. 
		# or:
		# echo "Mapping with bowtie..."
		# bowtie2 -t -p 15 -q -x ${REFBN} -1 ${INPUTDIR}/${bn}.filteredreads_1P.fq.gz -2 ${INPUTDIR}/${bn}.filteredreads_2P.fq.gz -S ${OUTPUTDIR}/${bn}.sam &
		# ${SAMTOOLS} sort ${OUTPUTDIR}/${bn}.bam > ${OUTPUTDIR}/${bn}.sorted.bam
		#
		# for sorting: 
		# -l 9:		maximum compression level. Default is 4 or 5. Trade-off between compression rate and compression time. 
		# -m 2048M:	maximum RAM memory per thread. So if using in total 3 samples with 10 threads each, then total RAM usage will be 3*10*2048. Default is 768M.
		#
		# To add reads groups at this step already, rather than at a later step, add:
		# -R @RG\tID:samplename\tSM:samplename\tPL:illumina\tLB:samplename
		done
	wait
	echo "Finished mapping data."
fi
	
if [[ "$getstats" = TRUE ]]
	then
	echo "Generating mapping statistics..."
	for bn in $(cat allsamples.bn.txt)
		do
		echo $bn
		${SAMTOOLS} flagstat ${OUTPUTDIR}/${bn}.sorted.bam > ${OUTPUTDIR}/${bn}.mappingstats.txt &
		done
	wait
	echo "Mapping statistics have been saved in files ending on 'mappingstats.txt'."
fi

if [[ "$indexbam" = TRUE ]]
	then
	echo "Indexing bam..."
	for bn in $(cat allsamples.bn.txt)
		do
		echo $bn
		${SAMTOOLS} index ${OUTPUTDIR}/${bn}.sorted.bam -@ 3 &
		# @: number of threads (although rarely above 130% anyway)
		done
	wait
	echo "Finished indexing."
fi	

if [[ "$addRG" = TRUE ]]
	then
	# uses up to 130% per sample, and 0.1% memory. So many samples can be run at the same time.
	# Around 2-3 hours per sample
	echo "Adding read groups..."
	for bn in $(cat allsamples.bn.txt)
		do
		echo $bn
		java -jar ${PICARD} AddOrReplaceReadGroups I=${OUTPUTDIR}/${bn}.sorted.bam O=${OUTPUTDIR}/${bn}.sorted.RG.bam RGID=${bn} RGPL=illumina RGPU=unit1 RGLB=${bn} RGSM=${bn} &
		# we set RGPL to illumina because novogene uses the illumina platform. we don't define platform unit (RGPU) 
		# rm ${OUTPUTDIR}/${bn}.sorted.bam 
		# rm ${OUTPUTDIR}/${bn}.sorted.bam.bai
		done
	wait
	echo "Finished adding read groups..."
fi

if [[ "$removedup" = TRUE ]]
	then
	echo "Marking and removing duplicates..."
	# CAREFUL: ONLY MAX 3 OR 4 SAMPLES SIMULTANEOUSLY!!!
	# next command spikes now and then up to 50 cores per sample (if available). 
	# Plus, depending on input bam-file size, can consume a lot of memory (in Cetus around 15% per sample)  
	# Therefore, I run maximum 3 samples at a time. 
	# the argument MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=1000 is included to avoid the error: 
	# Exception in thread "main" htsjdk.samtools.SAMException: /tmp/mdejong/CSPI.6051568413464160692.tmp/18682.tmpnot found. Caused by: java.io.FileNotFoundException: /tmp/mdejong/CSPI.6051568413464160692.tmp/18682.tmp (Too many open files)
	# the argument -Djava.io.tmpdir=picardtmp is included to avoid the error: java.io.IOException: No space left on device
	# BGI: --OPTICAL_DUPLICATE_PIXEL_DISTANCE 100 (default)
	# BGI: --OPTICAL_DUPLICATE_PIXEL_DISTANCE 2500 
	# If you receive an out of memory error, use a higher value for Xmx. You can use htop to observe how much RAM is available.
	for bn in $(cat allsamples.bn.txt)
		do
		echo $bn
		java -Xmx16g -Djava.io.tmpdir=picardtmp -jar ${PICARD} MarkDuplicates MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=1000 I=${OUTPUTDIR}/${bn}.sorted.RG.bam O=${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.bam M=${OUTPUTDIR}/${bn}.mark_dup_metrics.txt REMOVE_DUPLICATES=True   
		# if the process is killed, lower the value of the Xmx function
		#rm ${OUTPUTDIR}/${bn}.sorted.RG.bam
		done
	wait
	echo "Finished marking and removing duplicates."
fi

if [[ "$filterbam" = TRUE ]]
	then
	# takes approximately 1 hour per sample; assuming 3 cores can do around 20 samples at a time without clogging the system
	# q:		filter on mapping quality (--min-MQ)
	# h:		include header
	# b:		output in bam format
	# e:		filter on expression; '[AS]>=100' means: keep reads with an alignment score above 100		
	# f 0x2:	keep properly paired reads only
	# F4:		remove unmapped read
	# [AS]>=100 keep only reads with an alignment score of 100 or higher.
    #           Alignment score is calculated as follows: a match is 1, a mismatch is -4, a gap opening is -6, and a gap extension is -1.
    #           Also note that alignment score considers base qualities (if I am not mistaken).
    #           So you also can get a penalty if base quality score is below 13 (default value), meaning:  !"#$%&'()*+,-. (although not sure about the period)
	echo "Filtering on mapping quality and alignment score..."
	for bn in $(cat allsamples.bn.txt)
		do
		echo $bn
		if [[ "$paireddata" = TRUE ]]
			then
			${SAMTOOLS} view -@ $NRCORES -bhq 20 -f 0x2 -F4 -e '[AS]>=100' ${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.bam > ${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.filtered.bam &
			else
			${SAMTOOLS} view -@ $NRCORES -bhq 20 -F4 -e '[AS]>=100' ${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.bam > ${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.filtered.bam &
		fi
		#rm ${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.bam
		done
	wait
	echo "Finished filtering bam files."
fi

if [[ "$indexbam2" = TRUE ]]
	then
	echo "Indexing bam files..."
	for bn in $(cat allsamples.bn.txt)
		do
		echo $bn
		${SAMTOOLS} index ${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.filtered.bam -@ 3 &
		done
	wait
	echo "Finished indexing bam file."
fi

if [[ "$qualitycontrol" = TRUE ]]
	then
	echo "Performing quality control using qualimap bamqc..."
	# alternatively use sambamda or samtools-depth
	# note: first create a directory called bamqc-output
	for bn in $(cat allsamples.bn.txt)
		do
		echo $bn
		# nw: number of windows. with 30000 windows, assuming a genome of 3Gb, they window size will be around 100Kb.
		# Note though that increasing number of windows, will also increase computation time
		$QUALIMAP bamqc -bam ${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.filtered.bam -outdir ${OUTPUTDIR}/bamqc_output -outfile ${bn}_qualimap2.pdf -nt ${NRCORES} -nw 30000 --paint-chromosome-limits --java-mem-size=15G
		done
	wait
	echo "Finished quality control."
fi

if [[ "$removerepeats" = TRUE ]]
        then
        echo "Removing reads which mapped to repetitive regions..."
        for bn in $(cat allsamples.bn.txt)
            do
            echo $bn
            # Note: This command expects a bed-file listing repetitive regions, and will keep regions which do NOT overlap at all (-v option). 
			${BEDTOOLS} intersect -abam  ${INPUTDIR}/${bn}.sorted.RG.dupremoved.filtered.bam -b $REPEATFILE -v > ${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.filtered.repeatmasked.bam &
			# Only report those entries in A that have no overlap in B.
			# If, instead, you present a bed-file of regions which are NOT repetitive regions, such that you want to keep reads which overlap, then you need to run the opposite analysis.
			# In that case, you need to remove the -v option in.
			# Furthermore, you would have to add the -f 1 flag, indicating that you want to keep only those reads which overlap completely (i.e., overlap fraction is 1).
			# Otherwise you will also retain partially overlapping reads, which occur partly in non-repetitive regions.
			#
			# For the same reason, do not use samtools -L command:
			# ${SAMTOOLS} view -@ $NRCORES -L $REPEATFILE ${INPUTDIR}/${bn}.sorted.RG.dupremoved.filtered.bam > ${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.filtered.repeatmasked.bam &
			# -L, --targets-file FILE: Only output alignments overlapping the input BED FILE
			done
        wait
        echo "Reads have been removed. New output files have the suffix: 'sorted.RG.dupremoved.filtered.repeatmasked.bam'."
fi

if [[ "$indexbam3" = TRUE ]]
	then
	echo "Indexing bam file..."
	for bn in $(cat allsamples.bn.txt)
		do
		${SAMTOOLS} index ${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.filtered.repeatmasked.bam -@ 3 &
		done
	wait
	echo "Finished indexing bam file."
fi


# OPTIONALLY GENERATING QC REPORTS:

# echo "Validating bam file"
# java -jar ${PICARD} ValidateSamFile I=${OUTPUTDIR}/${bn}.sorted.RG.dupremoved.filtered.bam MODE=SUMMARY

# echo "Generating QC report..."
# Optionally install qualimap:
# conda activate conenv3.7
# conda install -c bioconda qualimap
	
# mkdir ${OUTPUTDIR}/QC_${bn}
# qualimap bamqc -bam $file -outdir ${OUTPUTDIR}/QC_${bn} -outfile ${OUTPUTDIR}/${bn}_qualimap2.pdf -nt 10 --java-mem-size=10G








############## UNDERSTANDING SAM/BAM-FORMAT ###############

# SAM FLAG (2nd column)
# Binary number composed of following elements:
# 0x1:		1		read paired
# 0x2: 		2		read mapped in proper pair
# 0x4:		4		read unmapped
# 0x8:		8		mate unmapped
# 0x16:		16		read reverse strand
# 0x20:		32		mate reverse strand
# 0x40: 	64		first in pair
# 0x80: 	128		second in pair
# 0x100: 	256		not primary alignment
# 0x200: 	512		read fails platform/vendor quality checks
# 0x400: 	1024	read is PCR or optical duplicates
# 0x800:	2048	supplementary alignment
 

# MAPPING QUALITY (5th column)
# Phred-scaled probability that read has been mapped to the wrong position in genome:
# MAPQ = -10*log10(pr_wrongly_mapped)
# Roughly: 
# Q10 = Pr(correctly mapped) = 90%. 
# Q20 = Pr(correctly mapped) = 99%. 
# Q30 = Pr(correctly mapped) = 99.9%. 
# Etc.
# BWA: 0-60; Bowtie: 0-42.
# In theory, probability depends on:
# 1. Contamination/sequencing errors
# 2. Mapping algorithm heuristics
# 3. Error due to the repetiveness of reference
# The MAPQ only considers the third factor.
# It compares the alignment score of the best alignment (AS:i) to the alignment score of the second-best alignment (XS:i). (See below for more info on AS and XS).
# If AS is much higher than XS, low probability of wrong mapping position (and thus high MAPQ value, close to 60).
# If AS==XS, MAPQ = 0.
# Note the MAPQ-score does not tell anything about the alignment itself.
# You can have a very shitty alignment (many gaps, many mismatches), but if the second best alignment is even much more shitty, then still high MAPQ score.
# If there is no second mapping position, MAPQ is set to maximum (60) in the case of BWA, and 255 in the case of Bowtie (?). 

# CIGAR STRING (6th column)
# describes alignment. Two examples:
# 150M:				optimal score for a read of 150bp, namely 150 matches/mismatches
# 23M2D50M2I57M6S:	23 matches/mismatches, 2 deletions, 50 matches, 2 insertions, 59 matches, 18 soft-clipped sites (segment at end of read that does not appear in alignment)  	

# AS:i:count
# alignment score.
# In case of BWA very simple: simply the number of matches. In the examples for CIGAR above, the alignment scores are respectively 150 and 132 (23 + 50 + 59).
# Note that 'i' simply indicates that this is an integer, and not a code (Z) for example.
 
# XS:i:count
# alignment score of second best alignment, if present

# MC:Z
# CIGAR string of second best alignment (or read pair mate?)

# MD:Z
# CIGAR string for reference (rather than query)

# NM:i:count
# Number of mismatches/deletions/insertions

# NH:i:2
# Number of regions in reference to which query could be aligned to









